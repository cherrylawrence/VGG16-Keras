{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553410560/553467096 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "model = VGG16()\n",
    "#print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load an image and resize it to the required size of 224Ã—224 pixels as per the VGG model\n",
    "orig = cv2.imread('mug.jpg')\n",
    "image = load_img('mug.jpg', target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_objects(image, model):\n",
    "    \"\"\"Takes a pre trained model(VGG16) and  an image and classifies that image\"\"\"\n",
    "    # convert the image pixels to a NumPy array so that it can work with Keras\n",
    "    image = img_to_array(image)\n",
    "    # input array will need to be 4-dimensional: samples, rows, columns, and channels.\n",
    "    # We only have one sample (one image). \n",
    "    # We can reshape the array by calling reshape() and adding the extra dimension.\n",
    "    # reshape data for the model\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    #the image pixels need to be prepared in the same way as the ImageNet training data was prepared\n",
    "    # prepare the image for the VGG model\n",
    "    image = preprocess_input(image)\n",
    "    # make a prediction\n",
    "    # predict the probability across all output classes\n",
    "    ypred = model.predict(image)\n",
    "    #  probabilities in case you would like to present the top 3 objects that may be in the photo.\n",
    "    # convert the probabilities to class labels\n",
    "    pred = decode_predictions(ypred)\n",
    "    print(pred[0])\n",
    "    for (i, (imagenetID, label, prob)) in enumerate(pred[0]):\n",
    "        print(\"{}. {}: {:.2f}%\".format(i + 1, label, prob * 100))\n",
    "    \n",
    "\n",
    "    # retrieve the most likely result, e.g. highest probability\n",
    "    label = pred[0][0]\n",
    "    # print the classification\n",
    "    print('%s (%.2f%%)' % (label[1], label[2]*100))\n",
    "    \n",
    "    # display the predictions to our screen\n",
    "    orig = cv2.imread('mug.jpg')\n",
    "    cv2.putText(orig, \"Label: {}\".format(label[1]), (10, 30),\n",
    "    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (130, 150, 120), 2)\n",
    "    cv2.imshow(\"Classification\", orig)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('n03063599', 'coffee_mug', 0.65496194), ('n07930864', 'cup', 0.15362585), ('n02948072', 'candle', 0.027709238), ('n03916031', 'perfume', 0.022822404), ('n03690938', 'lotion', 0.020030731)]\n",
      "1. coffee_mug: 65.50%\n",
      "2. cup: 15.36%\n",
      "3. candle: 2.77%\n",
      "4. perfume: 2.28%\n",
      "5. lotion: 2.00%\n",
      "coffee_mug (65.50%)\n"
     ]
    }
   ],
   "source": [
    "classify_objects(image, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
